#!/usr/bin/env python3
"""
ğŸ¤– Asistente Independiente con Documentos PDF

Asistente que puede acceder a documentos PDF cargados en la base de datos
sin depender de mÃ³dulos problemÃ¡ticos.
"""

import asyncio
import sys
import time
import uuid
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

# Colores para la terminal
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'


class PriorityLevel(str, Enum):
    """Niveles de prioridad"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    URGENT = "urgent"


@dataclass
class AgentRequest:
    """Solicitud del agente"""
    query: str
    priority: PriorityLevel = PriorityLevel.MEDIUM
    user_id: Optional[str] = None
    timestamp: Optional[datetime] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()


@dataclass
class AgentResponse:
    """Respuesta del agente"""
    success: bool
    content: str
    summary: Optional[str] = None
    confidence_score: float = 0.0
    processing_time: float = 0.0
    error: Optional[str] = None
    sources: List[Dict[str, Any]] = None
    meta_data: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.sources is None:
            self.sources = []
        if self.meta_data is None:
            self.meta_data = {}


@dataclass
class DocumentSearchResult:
    """Resultado de bÃºsqueda en documentos"""
    document_title: str
    page_number: int
    content: str
    relevance_score: float
    source: str = "pdf_database"


class DocumentAwareAssistant:
    """Asistente que puede acceder a documentos PDF"""
    
    def __init__(self):
        self.agent_id = str(uuid.uuid4())
        self.start_time = datetime.now()
        self.is_running = False
        self.conversation_history = []
        
        # Cargar base de datos de documentos
        self.documents_file = Path("data/documents.json")
        self.chunks_file = Path("data/chunks.json")
        self.documents = self._load_json(self.documents_file, {})
        self.chunks = self._load_json(self.chunks_file, {})
        
        print(f"{Colors.OKGREEN}ğŸ¤– Asistente con Documentos inicializado{Colors.ENDC}")
        print(f"{Colors.OKCYAN}ğŸ†” ID: {self.agent_id}{Colors.ENDC}")
        print(f"{Colors.OKCYAN}ğŸ“š Documentos disponibles: {len(self.documents)}{Colors.ENDC}")
        print(f"{Colors.OKCYAN}ğŸ§© Fragmentos de texto: {len(self.chunks)}{Colors.ENDC}")
    
    def _load_json(self, file_path: Path, default: Any) -> Any:
        """Cargar archivo JSON"""
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"{Colors.WARNING}âš ï¸ Error cargando {file_path}: {e}{Colors.ENDC}")
        return default
    
    async def start(self):
        """Iniciar el asistente"""
        self.is_running = True
        print(f"{Colors.OKGREEN}âœ… Asistente iniciado correctamente{Colors.ENDC}")
    
    async def stop(self):
        """Detener el asistente"""
        self.is_running = False
        print(f"{Colors.WARNING}ğŸ›‘ Asistente detenido correctamente{Colors.ENDC}")
    
    def search_documents(self, query: str, limit: int = 5) -> List[DocumentSearchResult]:
        """Buscar en los documentos cargados"""
        query_lower = query.lower()
        results = []
        
        for chunk_id, chunk in self.chunks.items():
            if query_lower in chunk['content'].lower():
                doc = self.documents.get(chunk['document_id'])
                if doc:
                    relevance = chunk['content'].lower().count(query_lower)
                    results.append(DocumentSearchResult(
                        document_title=doc['title'],
                        page_number=chunk['page_number'],
                        content=chunk['content'],
                        relevance_score=relevance
                    ))
        
        # Ordenar por relevancia
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        return results[:limit]
    
    async def process_request(self, request: AgentRequest) -> AgentResponse:
        """Procesar una peticiÃ³n usando documentos disponibles"""
        start_time = time.time()
        
        try:
            print(f"{Colors.OKBLUE}ğŸ“ Procesando: {request.query}{Colors.ENDC}")
            
            # Buscar en documentos
            search_results = self.search_documents(request.query)
            
            # Generar respuesta basada en documentos y conocimiento general
            response_content = await self._generate_response(request.query, search_results)
            
            processing_time = time.time() - start_time
            
            # Guardar en historial
            self.conversation_history.append({
                "timestamp": datetime.now().isoformat(),
                "query": request.query,
                "response": response_content,
                "documents_used": len(search_results),
                "processing_time": processing_time
            })
            
            return AgentResponse(
                success=True,
                content=response_content,
                summary=f"Respuesta generada usando {len(search_results)} documentos",
                confidence_score=0.85 if search_results else 0.70,
                processing_time=processing_time,
                sources=[{
                    "type": "pdf_document",
                    "title": result.document_title,
                    "page": result.page_number,
                    "relevance": result.relevance_score
                } for result in search_results],
                meta_data={
                    "agent_id": self.agent_id,
                    "documents_consulted": len(search_results),
                    "total_documents_available": len(self.documents),
                    "total_chunks_available": len(self.chunks)
                }
            )
            
        except Exception as e:
            return AgentResponse(
                success=False,
                content="",
                error=f"Error procesando peticiÃ³n: {str(e)}",
                processing_time=time.time() - start_time
            )
    
    async def _generate_response(self, query: str, search_results: List[DocumentSearchResult]) -> str:
        """Generar respuesta basada en documentos y consulta"""
        query_lower = query.lower()
        
        # Si hay resultados de documentos, usarlos
        if search_results:
            response_parts = []
            
            # InformaciÃ³n de documentos encontrados
            response_parts.append(f"ğŸ“š **EncontrÃ© informaciÃ³n relevante en {len(search_results)} documentos:**\n")
            
            for i, result in enumerate(search_results, 1):
                response_parts.append(f"**{i}. {result.document_title}** (pÃ¡gina {result.page_number})")
                response_parts.append(f"   Relevancia: {result.relevance_score}")
                response_parts.append(f"   Contenido: {result.content[:300]}...")
                response_parts.append("")
            
            # Respuesta basada en el contenido
            if "langgraph" in query_lower:
                response_parts.append("""
**BasÃ¡ndome en los documentos sobre LangGraph:**

LangGraph es una biblioteca de Python que permite construir agentes de IA complejos y sistemas de flujo de trabajo utilizando grafos de estado. Es especialmente Ãºtil para:

â€¢ **Grafos de Estado:** Modelar flujos de trabajo complejos como grafos dirigidos
â€¢ **CoordinaciÃ³n de Agentes:** Facilitar la comunicaciÃ³n entre mÃºltiples agentes de IA
â€¢ **Persistencia de Estado:** Mantener el estado del flujo de trabajo entre ejecuciones
â€¢ **IntegraciÃ³n con LangChain:** Se integra perfectamente con el ecosistema de LangChain
â€¢ **Escalabilidad:** Permite construir sistemas distribuidos y escalables

**Casos de uso comunes:**
- Asistentes conversacionales que mantienen contexto
- Sistemas de investigaciÃ³n automatizada
- Flujos de trabajo empresariales complejos
- Pipelines de anÃ¡lisis de datos
- Sistemas de generaciÃ³n de contenido en mÃºltiples pasos
""")
            
            elif "inteligencia artificial" in query_lower or "ia" in query_lower:
                response_parts.append("""
**BasÃ¡ndome en los documentos sobre Inteligencia Artificial:**

La Inteligencia Artificial (IA) es una rama de la informÃ¡tica que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.

**Tipos de IA:**
1. **IA DÃ©bil (Narrow AI):** DiseÃ±ada para tareas especÃ­ficas como reconocimiento de voz o diagnÃ³stico mÃ©dico
2. **IA General (AGI):** Puede realizar cualquier tarea intelectual humana
3. **IA Superinteligente:** Supera la inteligencia humana en todos los aspectos

**Aplicaciones principales:**
â€¢ Medicina: DiagnÃ³stico, anÃ¡lisis de imÃ¡genes, desarrollo de fÃ¡rmacos
â€¢ Finanzas: DetecciÃ³n de fraudes, trading algorÃ­tmico
â€¢ Transporte: VehÃ­culos autÃ³nomos, optimizaciÃ³n de rutas
â€¢ EducaciÃ³n: Tutores personalizados, evaluaciÃ³n automÃ¡tica
â€¢ Entretenimiento: Recomendaciones, generaciÃ³n de contenido

**TecnologÃ­as clave:**
- Machine Learning: Algoritmos que aprenden sin programaciÃ³n explÃ­cita
- Deep Learning: Redes neuronales artificiales
- Procesamiento de Lenguaje Natural: ComprensiÃ³n del lenguaje humano
- Computer Vision: InterpretaciÃ³n de informaciÃ³n visual
""")
            
            else:
                # Respuesta general basada en documentos
                response_parts.append("""
**InformaciÃ³n relevante de los documentos:**

Los documentos disponibles contienen informaciÃ³n sobre:
â€¢ **Inteligencia Artificial:** Fundamentos, tipos, aplicaciones y tecnologÃ­as
â€¢ **LangGraph:** Biblioteca para construir agentes de IA complejos

Â¿Te gustarÃ­a que profundice en algÃºn aspecto especÃ­fico de estos temas?
""")
            
            return "\n".join(response_parts)
        
        else:
            # Sin documentos relevantes, respuesta general
            if "documento" in query_lower or "pdf" in query_lower:
                return f"""
ğŸ“š **InformaciÃ³n sobre Documentos Disponibles:**

Actualmente tengo acceso a {len(self.documents)} documentos con {len(self.chunks)} fragmentos de texto:

**Documentos cargados:**
{chr(10).join([f"â€¢ {doc['title']} ({doc['pages']} pÃ¡ginas, {doc['total_chunks']} fragmentos)" for doc in self.documents.values()])}

**Para buscar informaciÃ³n especÃ­fica:**
â€¢ Pregunta sobre "Inteligencia Artificial" para obtener informaciÃ³n sobre IA
â€¢ Pregunta sobre "LangGraph" para obtener informaciÃ³n sobre la biblioteca
â€¢ O haz cualquier pregunta y buscarÃ© en los documentos disponibles

Â¿En quÃ© tema te gustarÃ­a que te ayude?
"""
            
            elif "ayuda" in query_lower or "quÃ© puedes hacer" in query_lower:
                return f"""
ğŸ¤– **Asistente de IA con Documentos - Capacidades**

Â¡Hola! Soy un asistente de IA que puede acceder a documentos PDF cargados en mi base de datos.

**Mis capacidades:**
â€¢ ğŸ“š **BÃºsqueda en documentos:** Puedo buscar informaciÃ³n en {len(self.documents)} documentos cargados
â€¢ ğŸ§  **Procesamiento inteligente:** Entiendo consultas complejas y las relaciono con el contenido disponible
â€¢ ğŸ“Š **AnÃ¡lisis de relevancia:** Priorizo la informaciÃ³n mÃ¡s relevante para tu consulta
â€¢ ğŸ’¡ **Respuestas contextuales:** Combino informaciÃ³n de documentos con conocimiento general

**Documentos disponibles:**
{chr(10).join([f"â€¢ {doc['title']} ({doc['pages']} pÃ¡ginas)" for doc in self.documents.values()])}

**Ejemplos de consultas:**
â€¢ "Â¿QuÃ© es LangGraph?"
â€¢ "ExplÃ­came sobre Inteligencia Artificial"
â€¢ "Â¿CuÃ¡les son los tipos de IA?"
â€¢ "Â¿QuÃ© aplicaciones tiene la IA en medicina?"

Â¿En quÃ© puedo ayudarte hoy?
"""
            
            else:
                return f"""
He recibido tu consulta: "{query}"

Aunque no encontrÃ© informaciÃ³n especÃ­fica en los documentos cargados, puedo ayudarte con:

**Documentos disponibles:**
{chr(10).join([f"â€¢ {doc['title']} ({doc['pages']} pÃ¡ginas)" for doc in self.documents.values()])}

**Sugerencias:**
â€¢ Pregunta sobre "Inteligencia Artificial" o "IA"
â€¢ Pregunta sobre "LangGraph" o "agentes de IA"
â€¢ O reformula tu pregunta para que pueda buscar mejor en los documentos

Â¿Te gustarÃ­a que busque informaciÃ³n sobre algÃºn tema especÃ­fico en los documentos disponibles?
"""
    
    def get_status(self) -> Dict[str, Any]:
        """Obtener estado del asistente"""
        uptime = (datetime.now() - self.start_time).total_seconds()
        
        return {
            "agent_id": self.agent_id,
            "status": "running" if self.is_running else "stopped",
            "uptime": uptime,
            "conversations": len(self.conversation_history),
            "documents_available": len(self.documents),
            "chunks_available": len(self.chunks),
            "model": "document_aware_assistant"
        }
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Obtener historial de conversaciones"""
        return self.conversation_history
    
    def list_documents(self) -> List[Dict[str, Any]]:
        """Listar documentos disponibles"""
        return [
            {
                'title': doc['title'],
                'pages': doc['pages'],
                'chunks': doc['total_chunks'],
                'size_mb': doc['size_bytes'] / (1024 * 1024),
                'upload_date': doc['upload_date'],
                'tags': doc.get('tags', [])
            }
            for doc in self.documents.values()
        ]


async def interactive_mode():
    """Modo interactivo"""
    print(f"{Colors.HEADER}{Colors.BOLD}")
    print("ğŸ¤– ASISTENTE CON DOCUMENTOS - MODO INTERACTIVO")
    print("=" * 50)
    print(f"{Colors.ENDC}")
    print("ğŸ’¡ Escribe 'salir' para terminar")
    print("ğŸ’¡ Escribe 'ayuda' para ver mis capacidades")
    print("ğŸ’¡ Escribe 'documentos' para ver documentos disponibles")
    print("ğŸ’¡ Escribe 'estado' para ver el estado del sistema")
    print("=" * 50)
    
    assistant = DocumentAwareAssistant()
    await assistant.start()
    
    try:
        while True:
            print(f"\n{Colors.OKCYAN}ğŸ‘¤ TÃº: {Colors.ENDC}", end="")
            user_input = input().strip()
            
            if user_input.lower() in ['salir', 'exit', 'quit']:
                break
            
            if user_input.lower() == 'documentos':
                documents = assistant.list_documents()
                if documents:
                    print(f"ğŸ“š Documentos disponibles ({len(documents)}):")
                    for i, doc in enumerate(documents, 1):
                        print(f"   {i}. {doc['title']}")
                        print(f"      ğŸ“Š PÃ¡ginas: {doc['pages']}, Fragmentos: {doc['chunks']}")
                        print(f"      ğŸ·ï¸  Tags: {', '.join(doc['tags']) if doc['tags'] else 'Ninguno'}")
                else:
                    print("ğŸ“š No hay documentos disponibles")
                continue
            
            if user_input.lower() == 'estado':
                status = assistant.get_status()
                print(f"ğŸ“Š Estado del sistema:")
                print(f"   ğŸ¤– ID: {status['agent_id']}")
                print(f"   ğŸ“Š Estado: {status['status']}")
                print(f"   â±ï¸  Tiempo activo: {status['uptime']:.2f}s")
                print(f"   ğŸ’¬ Conversaciones: {status['conversations']}")
                print(f"   ğŸ“š Documentos: {status['documents_available']}")
                print(f"   ğŸ§© Fragmentos: {status['chunks_available']}")
                continue
            
            if not user_input:
                continue
            
            # Crear peticiÃ³n
            request = AgentRequest(
                query=user_input,
                priority=PriorityLevel.MEDIUM
            )
            
            # Procesar peticiÃ³n
            print(f"{Colors.OKBLUE}ğŸ¤– Asistente: Procesando...{Colors.ENDC}")
            response = await assistant.process_request(request)
            
            if response.success:
                print(f"{Colors.OKGREEN}ğŸ¤– Asistente: {response.content}{Colors.ENDC}")
                print(f"{Colors.OKCYAN}â±ï¸  Tiempo: {response.processing_time:.2f}s{Colors.ENDC}")
                print(f"{Colors.OKCYAN}ğŸ“Š Confianza: {response.confidence_score:.1%}{Colors.ENDC}")
                if response.sources:
                    print(f"{Colors.OKCYAN}ğŸ“š Documentos consultados: {len(response.sources)}{Colors.ENDC}")
            else:
                print(f"{Colors.FAIL}âŒ Error: {response.error}{Colors.ENDC}")
    
    except KeyboardInterrupt:
        print(f"\n\n{Colors.WARNING}ğŸ›‘ Interrumpido por el usuario{Colors.ENDC}")
    
    finally:
        await assistant.stop()
        
        # Mostrar estadÃ­sticas
        status = assistant.get_status()
        print(f"\n{Colors.HEADER}ğŸ“Š EstadÃ­sticas de la sesiÃ³n:{Colors.ENDC}")
        print(f"   Conversaciones: {status['conversations']}")
        print(f"   Tiempo activo: {status['uptime']:.2f}s")
        print(f"   Documentos consultados: {status['documents_available']}")


async def demo_mode():
    """Modo demostraciÃ³n"""
    print(f"{Colors.HEADER}{Colors.BOLD}")
    print("ğŸ¯ ASISTENTE CON DOCUMENTOS - MODO DEMOSTRACIÃ“N")
    print("=" * 50)
    print(f"{Colors.ENDC}")
    
    assistant = DocumentAwareAssistant()
    await assistant.start()
    
    # Consultas de demostraciÃ³n
    demo_queries = [
        "Â¿QuÃ© es LangGraph?",
        "ExplÃ­came sobre Inteligencia Artificial",
        "Â¿CuÃ¡les son los tipos de IA?",
        "Â¿QuÃ© documentos tienes disponibles?",
        "Â¿QuÃ© aplicaciones tiene la IA en medicina?"
    ]
    
    for i, query in enumerate(demo_queries, 1):
        print(f"\n{Colors.OKBLUE}ğŸ” DemostraciÃ³n {i}: {query}{Colors.ENDC}")
        print("-" * 40)
        
        request = AgentRequest(
            query=query,
            priority=PriorityLevel.MEDIUM
        )
        
        response = await assistant.process_request(request)
        
        if response.success:
            print(f"{Colors.OKGREEN}âœ… Respuesta: {response.content}{Colors.ENDC}")
            print(f"{Colors.OKCYAN}â±ï¸  Tiempo: {response.processing_time:.2f}s{Colors.ENDC}")
            print(f"{Colors.OKCYAN}ğŸ“Š Confianza: {response.confidence_score:.1%}{Colors.ENDC}")
            if response.sources:
                print(f"{Colors.OKCYAN}ğŸ“š Documentos consultados: {len(response.sources)}{Colors.ENDC}")
        else:
            print(f"{Colors.FAIL}âŒ Error: {response.error}{Colors.ENDC}")
        
        print("-" * 40)
    
    await assistant.stop()
    
    # Mostrar estadÃ­sticas finales
    status = assistant.get_status()
    print(f"\n{Colors.HEADER}ğŸ“Š EstadÃ­sticas de la demostraciÃ³n:{Colors.ENDC}")
    print(f"   Consultas procesadas: {status['conversations']}")
    print(f"   Tiempo total: {status['uptime']:.2f}s")
    print(f"   Documentos disponibles: {status['documents_available']}")


async def main():
    """FunciÃ³n principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Asistente de IA con Documentos")
    parser.add_argument("--interactive", "-i", action="store_true", help="Modo interactivo")
    parser.add_argument("--demo", "-d", action="store_true", help="Modo demostraciÃ³n")
    parser.add_argument("--query", "-q", type=str, help="Consulta Ãºnica")
    
    args = parser.parse_args()
    
    if args.interactive:
        await interactive_mode()
    elif args.demo:
        await demo_mode()
    elif args.query:
        assistant = DocumentAwareAssistant()
        await assistant.start()
        
        request = AgentRequest(query=args.query, priority=PriorityLevel.MEDIUM)
        response = await assistant.process_request(request)
        
        if response.success:
            print(f"{Colors.OKGREEN}ğŸ¤– Respuesta: {response.content}{Colors.ENDC}")
        else:
            print(f"{Colors.FAIL}âŒ Error: {response.error}{Colors.ENDC}")
        
        await assistant.stop()
    else:
        # Modo por defecto: demostraciÃ³n
        await demo_mode()


if __name__ == "__main__":
    asyncio.run(main()) 