#!/usr/bin/env python3
"""
ðŸ¤– Agente Multimodal - Procesamiento de Texto e ImÃ¡genes

Este mÃ³dulo implementa un agente inteligente capaz de procesar tanto texto como imÃ¡genes,
integrando capacidades de visiÃ³n por computadora con el sistema RAG existente.
"""

import asyncio
import base64
import io
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
from enum import Enum

import aiohttp
import numpy as np
from PIL import Image
import fitz  # PyMuPDF

from .config import get_config
from .models_simple import AgentRequest, AgentResponse
from .intelligent_agent import IntelligentAgent

logger = logging.getLogger(__name__)


class ContentType(Enum):
    """Tipos de contenido que puede procesar el agente"""
    TEXT = "text"
    IMAGE = "image"
    PDF = "pdf"
    MULTIMODAL = "multimodal"


@dataclass
class ImageAnalysisResult:
    """Resultado del anÃ¡lisis de imagen"""
    content_type: ContentType
    text_content: Optional[str] = None
    image_description: Optional[str] = None
    objects_detected: List[str] = None
    ocr_text: Optional[str] = None
    confidence: float = 0.0
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.objects_detected is None:
            self.objects_detected = []
        if self.metadata is None:
            self.metadata = {}


class MultimodalAgent:
    """
    Agente Multimodal - Procesa texto e imÃ¡genes
    
    Integra capacidades de visiÃ³n por computadora con el sistema RAG existente
    para proporcionar anÃ¡lisis completo de contenido multimodal.
    """
    
    def __init__(self):
        self.config = get_config()
        self.text_agent = IntelligentAgent()
        
        # Servicios de visiÃ³n
        self.vision_services = {
            'openai_vision': self._analyze_with_openai_vision,
            'google_vision': self._analyze_with_google_vision,
            'azure_vision': self._analyze_with_azure_vision,
            'ocr': self._extract_text_with_ocr
        }
        
        # ConfiguraciÃ³n
        self.supported_image_formats = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}
        self.max_image_size = 20 * 1024 * 1024  # 20MB
        
    async def initialize(self):
        """Inicializar el agente multimodal"""
        try:
            logger.info("ðŸ¤– Inicializando agente multimodal...")
            
            # Inicializar agente de texto
            await self.text_agent.initialize()
            
            # Verificar servicios de visiÃ³n disponibles
            await self._check_vision_services()
            
            logger.info("âœ… Agente multimodal inicializado correctamente")
            
        except Exception as e:
            logger.error(f"âŒ Error inicializando agente multimodal: {e}")
            raise
    
    async def _check_vision_services(self):
        """Verificar quÃ© servicios de visiÃ³n estÃ¡n disponibles"""
        available_services = []
        
        # Verificar OpenAI Vision
        if self.config.openai_api_key:
            available_services.append('openai_vision')
        
        # Verificar Google Vision
        if hasattr(self.config, 'google_vision_api_key') and self.config.google_vision_api_key:
            available_services.append('google_vision')
        
        # Verificar Azure Vision
        if hasattr(self.config, 'azure_vision_endpoint') and self.config.azure_vision_endpoint:
            available_services.append('azure_vision')
        
        # OCR siempre disponible
        available_services.append('ocr')
        
        logger.info(f"ðŸ” Servicios de visiÃ³n disponibles: {available_services}")
        return available_services
    
    async def process_request(self, request: AgentRequest) -> AgentResponse:
        """Procesar una peticiÃ³n que puede contener texto e imÃ¡genes"""
        try:
            # Determinar tipo de contenido
            content_type = self._analyze_content_type(request)
            
            if content_type == ContentType.TEXT:
                # Usar agente de texto existente
                return await self.text_agent.process_request(request)
            
            elif content_type == ContentType.IMAGE:
                # Procesar imagen
                return await self._process_image_request(request)
            
            elif content_type == ContentType.PDF:
                # Procesar PDF (texto + imÃ¡genes)
                return await self._process_pdf_request(request)
            
            elif content_type == ContentType.MULTIMODAL:
                # Procesar contenido multimodal
                return await self._process_multimodal_request(request)
            
            else:
                raise ValueError(f"Tipo de contenido no soportado: {content_type}")
                
        except Exception as e:
            logger.error(f"âŒ Error procesando peticiÃ³n multimodal: {e}")
            return AgentResponse(
                success=False,
                content=f"Error procesando la peticiÃ³n: {str(e)}",
                metadata={"error": str(e)}
            )
    
    def _analyze_content_type(self, request: AgentRequest) -> ContentType:
        """Analizar el tipo de contenido de la peticiÃ³n"""
        query = request.query.lower()
        
        # Verificar si hay archivos adjuntos
        if hasattr(request, 'attachments') and request.attachments:
            return ContentType.MULTIMODAL
        
        # Verificar si es un PDF
        if query.endswith('.pdf') or 'pdf' in query:
            return ContentType.PDF
        
        # Verificar si menciona imÃ¡genes
        image_keywords = ['imagen', 'foto', 'imagen', 'grÃ¡fico', 'diagrama', 'chart', 'image', 'photo']
        if any(keyword in query for keyword in image_keywords):
            return ContentType.IMAGE
        
        # Por defecto, texto
        return ContentType.TEXT
    
    async def _process_image_request(self, request: AgentRequest) -> AgentResponse:
        """Procesar una peticiÃ³n que involucra imÃ¡genes"""
        try:
            # Extraer imagen de la peticiÃ³n
            image_data = await self._extract_image_from_request(request)
            
            if not image_data:
                return AgentResponse(
                    success=False,
                    content="No se encontrÃ³ ninguna imagen en la peticiÃ³n",
                    metadata={"error": "no_image_found"}
                )
            
            # Analizar imagen
            analysis_result = await self._analyze_image(image_data)
            
            # Generar respuesta basada en el anÃ¡lisis
            response_content = self._generate_image_response(analysis_result, request.query)
            
            return AgentResponse(
                success=True,
                content=response_content,
                metadata={
                    "content_type": "image_analysis",
                    "analysis_result": analysis_result.__dict__
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ Error procesando imagen: {e}")
            return AgentResponse(
                success=False,
                content=f"Error analizando la imagen: {str(e)}",
                metadata={"error": str(e)}
            )
    
    async def _extract_image_from_request(self, request: AgentRequest) -> Optional[bytes]:
        """Extraer datos de imagen de la peticiÃ³n"""
        # Implementar extracciÃ³n de imagen desde diferentes fuentes
        # - Archivos adjuntos
        # - URLs
        # - Base64
        # - Rutas de archivo
        pass
    
    async def _analyze_image(self, image_data: bytes) -> ImageAnalysisResult:
        """Analizar una imagen usando mÃºltiples servicios"""
        results = []
        
        # Procesar con todos los servicios disponibles
        for service_name, service_func in self.vision_services.items():
            try:
                result = await service_func(image_data)
                if result:
                    results.append(result)
            except Exception as e:
                logger.warning(f"âš ï¸ Error con servicio {service_name}: {e}")
        
        # Combinar resultados
        return self._combine_analysis_results(results)
    
    async def _analyze_with_openai_vision(self, image_data: bytes) -> Optional[ImageAnalysisResult]:
        """Analizar imagen usando OpenAI Vision (GPT-4V)"""
        try:
            # Implementar anÃ¡lisis con GPT-4V
            # Convertir imagen a base64
            image_b64 = base64.b64encode(image_data).decode('utf-8')
            
            # Llamar a OpenAI Vision API
            # (ImplementaciÃ³n especÃ­fica aquÃ­)
            
            return ImageAnalysisResult(
                content_type=ContentType.IMAGE,
                image_description="DescripciÃ³n de la imagen",
                confidence=0.9
            )
            
        except Exception as e:
            logger.error(f"âŒ Error con OpenAI Vision: {e}")
            return None
    
    async def _analyze_with_google_vision(self, image_data: bytes) -> Optional[ImageAnalysisResult]:
        """Analizar imagen usando Google Vision API"""
        # Implementar Google Vision API
        pass
    
    async def _analyze_with_azure_vision(self, image_data: bytes) -> Optional[ImageAnalysisResult]:
        """Analizar imagen usando Azure Computer Vision"""
        # Implementar Azure Computer Vision
        pass
    
    async def _extract_text_with_ocr(self, image_data: bytes) -> Optional[ImageAnalysisResult]:
        """Extraer texto de imagen usando OCR"""
        try:
            # Usar Pillow para procesar imagen
            image = Image.open(io.BytesIO(image_data))
            
            # Implementar OCR (puede usar Tesseract, EasyOCR, etc.)
            # Por ahora, retornar resultado bÃ¡sico
            return ImageAnalysisResult(
                content_type=ContentType.IMAGE,
                ocr_text="Texto extraÃ­do de la imagen",
                confidence=0.8
            )
            
        except Exception as e:
            logger.error(f"âŒ Error con OCR: {e}")
            return None
    
    def _combine_analysis_results(self, results: List[ImageAnalysisResult]) -> ImageAnalysisResult:
        """Combinar resultados de mÃºltiples servicios de anÃ¡lisis"""
        if not results:
            return ImageAnalysisResult(content_type=ContentType.IMAGE)
        
        # Combinar resultados de manera inteligente
        combined = ImageAnalysisResult(content_type=ContentType.IMAGE)
        
        # Combinar descripciones
        descriptions = [r.image_description for r in results if r.image_description]
        if descriptions:
            combined.image_description = " ".join(descriptions)
        
        # Combinar texto OCR
        ocr_texts = [r.ocr_text for r in results if r.ocr_text]
        if ocr_texts:
            combined.ocr_text = " ".join(ocr_texts)
        
        # Combinar objetos detectados
        all_objects = []
        for result in results:
            if result.objects_detected:
                all_objects.extend(result.objects_detected)
        combined.objects_detected = list(set(all_objects))
        
        # Calcular confianza promedio
        confidences = [r.confidence for r in results if r.confidence > 0]
        if confidences:
            combined.confidence = sum(confidences) / len(confidences)
        
        return combined
    
    def _generate_image_response(self, analysis: ImageAnalysisResult, query: str) -> str:
        """Generar respuesta basada en el anÃ¡lisis de imagen"""
        response_parts = []
        
        # Respuesta principal
        response_parts.append("ðŸ” **AnÃ¡lisis de Imagen Completado**")
        response_parts.append("")
        
        # DescripciÃ³n de la imagen
        if analysis.image_description:
            response_parts.append(f"ðŸ“· **DescripciÃ³n:** {analysis.image_description}")
            response_parts.append("")
        
        # Texto extraÃ­do
        if analysis.ocr_text:
            response_parts.append(f"ðŸ“ **Texto detectado:** {analysis.ocr_text}")
            response_parts.append("")
        
        # Objetos detectados
        if analysis.objects_detected:
            response_parts.append(f"ðŸŽ¯ **Objetos detectados:** {', '.join(analysis.objects_detected)}")
            response_parts.append("")
        
        # Confianza
        response_parts.append(f"ðŸŽ¯ **Confianza del anÃ¡lisis:** {analysis.confidence:.1%}")
        
        return "\n".join(response_parts)
    
    async def _process_pdf_request(self, request: AgentRequest) -> AgentResponse:
        """Procesar una peticiÃ³n que involucra PDFs"""
        # Implementar procesamiento de PDFs con imÃ¡genes
        pass
    
    async def _process_multimodal_request(self, request: AgentRequest) -> AgentResponse:
        """Procesar una peticiÃ³n multimodal (texto + imÃ¡genes)"""
        # Implementar procesamiento multimodal
        pass


# FunciÃ³n de conveniencia para crear el agente
async def create_multimodal_agent() -> MultimodalAgent:
    """Crear y configurar un agente multimodal"""
    agent = MultimodalAgent()
    await agent.initialize()
    return agent 