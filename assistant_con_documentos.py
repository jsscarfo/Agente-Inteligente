#!/usr/bin/env python3
"""
ğŸ¤– Asistente de IA con Documentos PDF

Asistente que puede acceder a documentos PDF cargados en la base de datos
y responder preguntas basÃ¡ndose en esa informaciÃ³n.
"""

import asyncio
import sys
import time
import uuid
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# AÃ±adir el directorio del proyecto al path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from agent.core.models_simple import AgentRequest, AgentResponse, PriorityLevel


@dataclass
class DocumentSearchResult:
    """Resultado de bÃºsqueda en documentos"""
    document_title: str
    page_number: int
    content: str
    relevance_score: float
    source: str = "pdf_database"


class DocumentAwareAssistant:
    """Asistente que puede acceder a documentos PDF"""
    
    def __init__(self):
        self.agent_id = str(uuid.uuid4())
        self.start_time = datetime.now()
        self.is_running = False
        self.conversation_history = []
        
        # Cargar base de datos de documentos
        self.documents_file = Path("data/documents.json")
        self.chunks_file = Path("data/chunks.json")
        self.documents = self._load_json(self.documents_file, {})
        self.chunks = self._load_json(self.chunks_file, {})
        
        print(f"ğŸ¤– Asistente con Documentos inicializado")
        print(f"ğŸ†” ID: {self.agent_id}")
        print(f"ğŸ“š Documentos disponibles: {len(self.documents)}")
        print(f"ğŸ§© Fragmentos de texto: {len(self.chunks)}")
    
    def _load_json(self, file_path: Path, default: Any) -> Any:
        """Cargar archivo JSON"""
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ Error cargando {file_path}: {e}")
        return default
    
    async def start(self):
        """Iniciar el asistente"""
        self.is_running = True
        print("âœ… Asistente iniciado correctamente")
    
    async def stop(self):
        """Detener el asistente"""
        self.is_running = False
        print("ğŸ›‘ Asistente detenido correctamente")
    
    def search_documents(self, query: str, limit: int = 5) -> List[DocumentSearchResult]:
        """Buscar en los documentos cargados"""
        query_lower = query.lower()
        results = []
        
        for chunk_id, chunk in self.chunks.items():
            if query_lower in chunk['content'].lower():
                doc = self.documents.get(chunk['document_id'])
                if doc:
                    relevance = chunk['content'].lower().count(query_lower)
                    results.append(DocumentSearchResult(
                        document_title=doc['title'],
                        page_number=chunk['page_number'],
                        content=chunk['content'],
                        relevance_score=relevance
                    ))
        
        # Ordenar por relevancia
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        return results[:limit]
    
    async def process_request(self, request: AgentRequest) -> AgentResponse:
        """Procesar una peticiÃ³n usando documentos disponibles"""
        start_time = time.time()
        
        try:
            print(f"ğŸ“ Procesando: {request.query}")
            
            # Buscar en documentos
            search_results = self.search_documents(request.query)
            
            # Generar respuesta basada en documentos y conocimiento general
            response_content = await self._generate_response(request.query, search_results)
            
            processing_time = time.time() - start_time
            
            # Guardar en historial
            self.conversation_history.append({
                "timestamp": datetime.now().isoformat(),
                "query": request.query,
                "response": response_content,
                "documents_used": len(search_results),
                "processing_time": processing_time
            })
            
            return AgentResponse(
                success=True,
                content=response_content,
                summary=f"Respuesta generada usando {len(search_results)} documentos",
                confidence_score=0.85 if search_results else 0.70,
                processing_time=processing_time,
                sources=[{
                    "type": "pdf_document",
                    "title": result.document_title,
                    "page": result.page_number,
                    "relevance": result.relevance_score
                } for result in search_results],
                meta_data={
                    "agent_id": self.agent_id,
                    "documents_consulted": len(search_results),
                    "total_documents_available": len(self.documents),
                    "total_chunks_available": len(self.chunks)
                }
            )
            
        except Exception as e:
            return AgentResponse(
                success=False,
                content="",
                error=f"Error procesando peticiÃ³n: {str(e)}",
                processing_time=time.time() - start_time
            )
    
    async def _generate_response(self, query: str, search_results: List[DocumentSearchResult]) -> str:
        """Generar respuesta basada en documentos y consulta"""
        query_lower = query.lower()
        
        # Si hay resultados de documentos, usarlos
        if search_results:
            response_parts = []
            
            # InformaciÃ³n de documentos encontrados
            response_parts.append(f"ğŸ“š **EncontrÃ© informaciÃ³n relevante en {len(search_results)} documentos:**\n")
            
            for i, result in enumerate(search_results, 1):
                response_parts.append(f"**{i}. {result.document_title}** (pÃ¡gina {result.page_number})")
                response_parts.append(f"   Relevancia: {result.relevance_score}")
                response_parts.append(f"   Contenido: {result.content[:300]}...")
                response_parts.append("")
            
            # Respuesta basada en el contenido
            if "langgraph" in query_lower:
                response_parts.append("""
**BasÃ¡ndome en los documentos sobre LangGraph:**

LangGraph es una biblioteca de Python que permite construir agentes de IA complejos y sistemas de flujo de trabajo utilizando grafos de estado. Es especialmente Ãºtil para:

â€¢ **Grafos de Estado:** Modelar flujos de trabajo complejos como grafos dirigidos
â€¢ **CoordinaciÃ³n de Agentes:** Facilitar la comunicaciÃ³n entre mÃºltiples agentes de IA
â€¢ **Persistencia de Estado:** Mantener el estado del flujo de trabajo entre ejecuciones
â€¢ **IntegraciÃ³n con LangChain:** Se integra perfectamente con el ecosistema de LangChain
â€¢ **Escalabilidad:** Permite construir sistemas distribuidos y escalables

**Casos de uso comunes:**
- Asistentes conversacionales que mantienen contexto
- Sistemas de investigaciÃ³n automatizada
- Flujos de trabajo empresariales complejos
- Pipelines de anÃ¡lisis de datos
- Sistemas de generaciÃ³n de contenido en mÃºltiples pasos
""")
            
            elif "inteligencia artificial" in query_lower or "ia" in query_lower:
                response_parts.append("""
**BasÃ¡ndome en los documentos sobre Inteligencia Artificial:**

La Inteligencia Artificial (IA) es una rama de la informÃ¡tica que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.

**Tipos de IA:**
1. **IA DÃ©bil (Narrow AI):** DiseÃ±ada para tareas especÃ­ficas como reconocimiento de voz o diagnÃ³stico mÃ©dico
2. **IA General (AGI):** Puede realizar cualquier tarea intelectual humana
3. **IA Superinteligente:** Supera la inteligencia humana en todos los aspectos

**Aplicaciones principales:**
â€¢ Medicina: DiagnÃ³stico, anÃ¡lisis de imÃ¡genes, desarrollo de fÃ¡rmacos
â€¢ Finanzas: DetecciÃ³n de fraudes, trading algorÃ­tmico
â€¢ Transporte: VehÃ­culos autÃ³nomos, optimizaciÃ³n de rutas
â€¢ EducaciÃ³n: Tutores personalizados, evaluaciÃ³n automÃ¡tica
â€¢ Entretenimiento: Recomendaciones, generaciÃ³n de contenido

**TecnologÃ­as clave:**
- Machine Learning: Algoritmos que aprenden sin programaciÃ³n explÃ­cita
- Deep Learning: Redes neuronales artificiales
- Procesamiento de Lenguaje Natural: ComprensiÃ³n del lenguaje humano
- Computer Vision: InterpretaciÃ³n de informaciÃ³n visual
""")
            
            else:
                # Respuesta general basada en documentos
                response_parts.append("""
**InformaciÃ³n relevante de los documentos:**

Los documentos disponibles contienen informaciÃ³n sobre:
â€¢ **Inteligencia Artificial:** Fundamentos, tipos, aplicaciones y tecnologÃ­as
â€¢ **LangGraph:** Biblioteca para construir agentes de IA complejos

Â¿Te gustarÃ­a que profundice en algÃºn aspecto especÃ­fico de estos temas?
""")
            
            return "\n".join(response_parts)
        
        else:
            # Sin documentos relevantes, respuesta general
            if "documento" in query_lower or "pdf" in query_lower:
                return f"""
ğŸ“š **InformaciÃ³n sobre Documentos Disponibles:**

Actualmente tengo acceso a {len(self.documents)} documentos con {len(self.chunks)} fragmentos de texto:

**Documentos cargados:**
{chr(10).join([f"â€¢ {doc['title']} ({doc['pages']} pÃ¡ginas, {doc['total_chunks']} fragmentos)" for doc in self.documents.values()])}

**Para buscar informaciÃ³n especÃ­fica:**
â€¢ Pregunta sobre "Inteligencia Artificial" para obtener informaciÃ³n sobre IA
â€¢ Pregunta sobre "LangGraph" para obtener informaciÃ³n sobre la biblioteca
â€¢ O haz cualquier pregunta y buscarÃ© en los documentos disponibles

Â¿En quÃ© tema te gustarÃ­a que te ayude?
"""
            
            elif "ayuda" in query_lower or "quÃ© puedes hacer" in query_lower:
                return f"""
ğŸ¤– **Asistente de IA con Documentos - Capacidades**

Â¡Hola! Soy un asistente de IA que puede acceder a documentos PDF cargados en mi base de datos.

**Mis capacidades:**
â€¢ ğŸ“š **BÃºsqueda en documentos:** Puedo buscar informaciÃ³n en {len(self.documents)} documentos cargados
â€¢ ğŸ§  **Procesamiento inteligente:** Entiendo consultas complejas y las relaciono con el contenido disponible
â€¢ ğŸ“Š **AnÃ¡lisis de relevancia:** Priorizo la informaciÃ³n mÃ¡s relevante para tu consulta
â€¢ ğŸ’¡ **Respuestas contextuales:** Combino informaciÃ³n de documentos con conocimiento general

**Documentos disponibles:**
{chr(10).join([f"â€¢ {doc['title']} ({doc['pages']} pÃ¡ginas)" for doc in self.documents.values()])}

**Ejemplos de consultas:**
â€¢ "Â¿QuÃ© es LangGraph?"
â€¢ "ExplÃ­came sobre Inteligencia Artificial"
â€¢ "Â¿CuÃ¡les son los tipos de IA?"
â€¢ "Â¿QuÃ© aplicaciones tiene la IA en medicina?"

Â¿En quÃ© puedo ayudarte hoy?
"""
            
            else:
                return f"""
He recibido tu consulta: "{query}"

Aunque no encontrÃ© informaciÃ³n especÃ­fica en los documentos cargados, puedo ayudarte con:

**Documentos disponibles:**
{chr(10).join([f"â€¢ {doc['title']} ({doc['pages']} pÃ¡ginas)" for doc in self.documents.values()])}

**Sugerencias:**
â€¢ Pregunta sobre "Inteligencia Artificial" o "IA"
â€¢ Pregunta sobre "LangGraph" o "agentes de IA"
â€¢ O reformula tu pregunta para que pueda buscar mejor en los documentos

Â¿Te gustarÃ­a que busque informaciÃ³n sobre algÃºn tema especÃ­fico en los documentos disponibles?
"""
    
    def get_status(self) -> Dict[str, Any]:
        """Obtener estado del asistente"""
        uptime = (datetime.now() - self.start_time).total_seconds()
        
        return {
            "agent_id": self.agent_id,
            "status": "running" if self.is_running else "stopped",
            "uptime": uptime,
            "conversations": len(self.conversation_history),
            "documents_available": len(self.documents),
            "chunks_available": len(self.chunks),
            "model": "document_aware_assistant"
        }
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Obtener historial de conversaciones"""
        return self.conversation_history
    
    def list_documents(self) -> List[Dict[str, Any]]:
        """Listar documentos disponibles"""
        return [
            {
                'title': doc['title'],
                'pages': doc['pages'],
                'chunks': doc['total_chunks'],
                'size_mb': doc['size_bytes'] / (1024 * 1024),
                'upload_date': doc['upload_date'],
                'tags': doc.get('tags', [])
            }
            for doc in self.documents.values()
        ]


async def interactive_mode():
    """Modo interactivo"""
    print("ğŸ¤– ASISTENTE CON DOCUMENTOS - MODO INTERACTIVO")
    print("=" * 50)
    print("ğŸ’¡ Escribe 'salir' para terminar")
    print("ğŸ’¡ Escribe 'ayuda' para ver mis capacidades")
    print("ğŸ’¡ Escribe 'documentos' para ver documentos disponibles")
    print("ğŸ’¡ Escribe 'estado' para ver el estado del sistema")
    print("=" * 50)
    
    assistant = DocumentAwareAssistant()
    await assistant.start()
    
    try:
        while True:
            print(f"\nğŸ‘¤ TÃº: ", end="")
            user_input = input().strip()
            
            if user_input.lower() in ['salir', 'exit', 'quit']:
                break
            
            if user_input.lower() == 'documentos':
                documents = assistant.list_documents()
                if documents:
                    print(f"ğŸ“š Documentos disponibles ({len(documents)}):")
                    for i, doc in enumerate(documents, 1):
                        print(f"   {i}. {doc['title']}")
                        print(f"      ğŸ“Š PÃ¡ginas: {doc['pages']}, Fragmentos: {doc['chunks']}")
                        print(f"      ğŸ·ï¸  Tags: {', '.join(doc['tags']) if doc['tags'] else 'Ninguno'}")
                else:
                    print("ğŸ“š No hay documentos disponibles")
                continue
            
            if not user_input:
                continue
            
            # Crear peticiÃ³n
            request = AgentRequest(
                query=user_input,
                priority=PriorityLevel.MEDIUM
            )
            
            # Procesar peticiÃ³n
            print("ğŸ¤– Asistente: Procesando...")
            response = await assistant.process_request(request)
            
            if response.success:
                print(f"ğŸ¤– Asistente: {response.content}")
                print(f"â±ï¸  Tiempo: {response.processing_time:.2f}s")
                print(f"ğŸ“Š Confianza: {response.confidence_score:.1%}")
                if response.sources:
                    print(f"ğŸ“š Documentos consultados: {len(response.sources)}")
            else:
                print(f"âŒ Error: {response.error}")
    
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Interrumpido por el usuario")
    
    finally:
        await assistant.stop()
        
        # Mostrar estadÃ­sticas
        status = assistant.get_status()
        print(f"\nğŸ“Š EstadÃ­sticas de la sesiÃ³n:")
        print(f"   Conversaciones: {status['conversations']}")
        print(f"   Tiempo activo: {status['uptime']:.2f}s")
        print(f"   Documentos consultados: {status['documents_available']}")


async def demo_mode():
    """Modo demostraciÃ³n"""
    print("ğŸ¯ ASISTENTE CON DOCUMENTOS - MODO DEMOSTRACIÃ“N")
    print("=" * 50)
    
    assistant = DocumentAwareAssistant()
    await assistant.start()
    
    # Consultas de demostraciÃ³n
    demo_queries = [
        "Â¿QuÃ© es LangGraph?",
        "ExplÃ­came sobre Inteligencia Artificial",
        "Â¿CuÃ¡les son los tipos de IA?",
        "Â¿QuÃ© documentos tienes disponibles?",
        "Â¿QuÃ© aplicaciones tiene la IA en medicina?"
    ]
    
    for i, query in enumerate(demo_queries, 1):
        print(f"\nğŸ” DemostraciÃ³n {i}: {query}")
        print("-" * 40)
        
        request = AgentRequest(
            query=query,
            priority=PriorityLevel.MEDIUM
        )
        
        response = await assistant.process_request(request)
        
        if response.success:
            print(f"âœ… Respuesta: {response.content}")
            print(f"â±ï¸  Tiempo: {response.processing_time:.2f}s")
            print(f"ğŸ“Š Confianza: {response.confidence_score:.1%}")
            if response.sources:
                print(f"ğŸ“š Documentos consultados: {len(response.sources)}")
        else:
            print(f"âŒ Error: {response.error}")
        
        print("-" * 40)
    
    await assistant.stop()
    
    # Mostrar estadÃ­sticas finales
    status = assistant.get_status()
    print(f"\nğŸ“Š EstadÃ­sticas de la demostraciÃ³n:")
    print(f"   Consultas procesadas: {status['conversations']}")
    print(f"   Tiempo total: {status['uptime']:.2f}s")
    print(f"   Documentos disponibles: {status['documents_available']}")


async def main():
    """FunciÃ³n principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Asistente de IA con Documentos")
    parser.add_argument("--interactive", "-i", action="store_true", help="Modo interactivo")
    parser.add_argument("--demo", "-d", action="store_true", help="Modo demostraciÃ³n")
    parser.add_argument("--query", "-q", type=str, help="Consulta Ãºnica")
    
    args = parser.parse_args()
    
    if args.interactive:
        await interactive_mode()
    elif args.demo:
        await demo_mode()
    elif args.query:
        assistant = DocumentAwareAssistant()
        await assistant.start()
        
        request = AgentRequest(query=args.query, priority=PriorityLevel.MEDIUM)
        response = await assistant.process_request(request)
        
        if response.success:
            print(f"ğŸ¤– Respuesta: {response.content}")
        else:
            print(f"âŒ Error: {response.error}")
        
        await assistant.stop()
    else:
        # Modo por defecto: demostraciÃ³n
        await demo_mode()


if __name__ == "__main__":
    asyncio.run(main()) 